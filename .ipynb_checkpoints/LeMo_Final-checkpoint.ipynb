{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62711c07-72a7-4da7-ba60-ab3184806ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Welcome to LeMo, an app that uses voice memos to fill out online surveys!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfda7ae0-aad8-4498-85f2-1a32ceea45f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydub in ./Library/Python/3.11/lib/python/site-packages (0.25.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ae2fa5-cee2-4c9e-bd22-8c09bf445649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherbail/Library/Python/3.11/lib/python/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/christopherbail/Library/Python/3.11/lib/python/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/christopherbail/Library/Python/3.11/lib/python/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/christopherbail/Library/Python/3.11/lib/python/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename  \\\n",
      "0  Lemur_Ln_7.m4a   \n",
      "1  Lemur_Ln_6.m4a   \n",
      "2  Lemur_Ln_2.m4a   \n",
      "3  Lemur_Ln_3.m4a   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       transcription  \n",
      "0                                            Okay, when you're ready. Ready to go? Okay. This is Dr. Johnson working with Raven today. Raven is a fat-tailed dwarf lemur. Today is September 8th, 2025. We started working with Raven at 8.50 and we're done by 9 a.m. She was in-hand for a brief examination and pregnancy check. There were no complications during handling. During handling she was biting the handler gloves, but there were no further complications encountered during the handling event. Captured was easy and there were no significant complications as a result of this handling event. The doctor was in-hand for a brief examination. The doctor was in-hand for a brief examination. The doctor was in-hand for a brief examination. The doctor was in-hand for a brief examination. The doctor was in-hand for a brief examination.  \n",
      "1   This is an animal assessment for blue-eyed black lemur geller. Completed on September 8th, 2025, recorded by Julie T.B. The primary handler is Julie T.B. The secondary handler is Kat Ostraski. The start time was 11-10. The end time was 11-15. For a total duration of five minutes. The reason for handling was a blood draw and an inhand exam. Geller had a nose bleed and she was open mouth breathing during restraint. Restraint extended for more than one minute. And she was actively resisting handling during restraint. She didn't have any other significant or adverse events during restraint. Just nose bleed and open mouth breathing. Perfect. And now I'm hoping that record against... Can that create a new recording? Oh, really? So how I stop. I can do it again. No, no, I think I've got it. There it is. Yeah, I'll just cut off.  \n",
      "2                                                                                                                                                                                                                                                                                                                This is Danielle Lynch. I am handling with Shafak Yohan on Tuesday, which is 7-23-25. I was the primary handler and Catherine was the second dairy handler. The start time was 406 and the end time was 4-10. The reason for handling was to place a collar. During handling there were indicators of stress such as break dancing and laying on the back. The catch category was average. The handling category was active. There were no significant events during this handling event and Yohan recovered well and did not overheat during this.  \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                 This is Danielle Lynch. I am handling Virginia Creeper who is a mouse lemur today. I was a primary handler and Ali was the secondary handler. We started at 10 a.m. and ended at 10.04. The reason for handling was weighing and open mouth was one of the indicators of stress. The catch category was fast. The handling category was passive and there were no significant events or adverse events during this handling event.  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define folder path explicitly\n",
    "base_dir = \"/Users/christopherbail/Dropbox/LEMO/\"\n",
    "folder_path = os.path.join(base_dir, \"memos\")\n",
    "\n",
    "# Step 2: Load Whisper model once\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Step 3: Prepare storage for results\n",
    "transcriptions = []\n",
    "\n",
    "# Step 4: Loop through all files in the \"memos\" folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".m4a\", \".mp3\", \".wav\")):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Convert audio to WAV (temporary)\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        temp_wav = os.path.join(base_dir, \"temp.wav\")  # store temp in base dir\n",
    "        audio.export(temp_wav, format=\"wav\")\n",
    "\n",
    "        # Transcribe\n",
    "        result = model.transcribe(temp_wav)\n",
    "\n",
    "        # Store results\n",
    "        transcriptions.append({\n",
    "            \"filename\": filename,\n",
    "            \"transcription\": result[\"text\"]\n",
    "        })\n",
    "\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_wav):\n",
    "            os.remove(temp_wav)\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "df = pd.DataFrame(transcriptions)\n",
    "\n",
    "# Example: print or save to CSV\n",
    "\n",
    "#print full text of transcription\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(df)\n",
    "# df.to_csv(os.path.join(base_dir, \"transcriptions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f92cb-b6e2-4282-8958-9dbe4eb78045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3371e8d5-ad3b-4b2f-98db-0ebc7eba2488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 questions.\n",
      "First few keys: ['animal_name', 'capture_notes_v2v2', 'catch_categoryv2', 'chkn_handling_hubandry_v2v2', 'chkn_qrbehavior', 'end_v2v2', 'handling_categoryv2', 'handling_date_v2v2', 'handling_hubandry_other_v2v2', 'handling_notes_v2v2']\n",
      "✅ Wrote 4 rows to /Users/christopherbail/Dropbox/LEMO/survey_responses.csv\n",
      "Columns: 23\n",
      "['filename', 'animal_name', 'capture_notes_v2v2', 'catch_categoryv2', 'chkn_handling_hubandry_v2v2', 'chkn_qrbehavior', 'end_v2v2', 'handling_categoryv2', 'handling_date_v2v2', 'handling_hubandry_other_v2v2', 'handling_notes_v2v2', 'handling_recorder_v2v2']\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, unicodedata\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# SETTINGS (adjust paths as needed)\n",
    "# --------------------------------------------------------------------------------\n",
    "SURVEY_HTML_PATH = \"/Users/christopherbail/Dropbox/LEMO/Animal Handling Assessment QR.html\"\n",
    "OUTPUT_CSV_PATH  = \"/Users/christopherbail/Dropbox/LEMO/survey_responses.csv\"\n",
    "\n",
    "# This script expects df to exist with columns: [\"filename\", \"transcription\"]\n",
    "# Example:\n",
    "# df = pd.DataFrame([{\"filename\":\"memo1.m4a\",\"transcription\":\"...\"},\n",
    "#                    {\"filename\":\"memo2.m4a\",\"transcription\":\"...\"}])\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# API key (prompted securely)\n",
    "# --------------------------------------------------------------------------------\n",
    "api_key = getpass.getpass(\"Please enter your OpenAI API key: \").strip()\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# --------------------------------------------------------------------------------\n",
    "def normalize_key(s: str) -> str:\n",
    "    \"\"\"Canonicalize a field name: lowercase, strip accents, non-alnum->'_', collapse underscores.\"\"\"\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = s.strip().lower()\n",
    "    s = \"\".join(ch if ch.isalnum() else \"_\" for ch in s)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "def get_label_for_input(tag: BeautifulSoup) -> str:\n",
    "    \"\"\"Find a human-friendly label for an input/select/textarea.\"\"\"\n",
    "    # 1) <label for=\"id\">\n",
    "    if tag.has_attr(\"id\"):\n",
    "        # search anywhere in the document for a label pointing to this id\n",
    "        doc = tag if tag.parent is None else tag.find_parent()\n",
    "        while doc and doc.parent:\n",
    "            doc = doc.parent  # bubble up to root\n",
    "        if doc:\n",
    "            lbl = doc.find(\"label\", attrs={\"for\": tag[\"id\"]})\n",
    "            if lbl and lbl.get_text(strip=True):\n",
    "                return lbl.get_text(\" \", strip=True)\n",
    "\n",
    "    # 2) parent-wrapped label\n",
    "    parent_lbl = tag.find_parent(\"label\")\n",
    "    if parent_lbl and parent_lbl.get_text(strip=True):\n",
    "        return parent_lbl.get_text(\" \", strip=True)\n",
    "\n",
    "    # 3) preceding sibling label\n",
    "    prev = tag.find_previous_sibling(\"label\")\n",
    "    if prev and prev.get_text(strip=True):\n",
    "        return prev.get_text(\" \", strip=True)\n",
    "\n",
    "    # 4) nearby heading or prompt text (common in simple forms)\n",
    "    for prev_tag in tag.find_all_previous([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\",\"p\",\"div\"], limit=3):\n",
    "        txt = prev_tag.get_text(\" \", strip=True)\n",
    "        if txt and len(txt) <= 200:\n",
    "            return txt\n",
    "\n",
    "    # 5) fallbacks from attributes\n",
    "    for attr in (\"aria-label\", \"placeholder\", \"name\", \"id\"):\n",
    "        if tag.has_attr(attr) and tag[attr]:\n",
    "            return str(tag[attr])\n",
    "\n",
    "    return \"unknown_field\"\n",
    "\n",
    "def option_text_for_input(opt_tag, doc_root) -> str:\n",
    "    \"\"\"Get display text for an option (radio/checkbox/select).\"\"\"\n",
    "    # If it's a <option>, text is inside\n",
    "    if opt_tag.name == \"option\":\n",
    "        return opt_tag.get_text(\" \", strip=True) or (opt_tag.get(\"value\") or \"\").strip()\n",
    "\n",
    "    # For radio/checkbox, label often uses <label for=\"id\">\n",
    "    if opt_tag.has_attr(\"id\"):\n",
    "        lbl = doc_root.find(\"label\", attrs={\"for\": opt_tag[\"id\"]})\n",
    "        if lbl and lbl.get_text(strip=True):\n",
    "            return lbl.get_text(\" \", strip=True)\n",
    "\n",
    "    # Fallbacks\n",
    "    return (opt_tag.get(\"value\") or \"\").strip()\n",
    "\n",
    "def parse_survey_questions(html_text: str):\n",
    "    \"\"\"\n",
    "    Extract a canonical list of questions from the HTML.\n",
    "    Returns a list of dicts with:\n",
    "      - key: stable column key\n",
    "      - question: human-friendly question text\n",
    "      - input_type: 'text' | 'textarea' | 'select' | 'radio' | 'checkbox' | other\n",
    "      - options: list of option strings (for select/radio/checkbox), else []\n",
    "    Groups radio/checkbox inputs by their 'name' (so one question per group).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "\n",
    "    # doc_root to help find labels by id across document\n",
    "    doc_root = soup\n",
    "    while doc_root.parent:\n",
    "        doc_root = doc_root.parent\n",
    "\n",
    "    questions = []\n",
    "    seen_keys = set()\n",
    "\n",
    "    # First, collect all controls\n",
    "    controls = soup.find_all([\"input\", \"select\", \"textarea\"])\n",
    "\n",
    "    # Group radio/checkbox by name\n",
    "    groups = {}\n",
    "    for tag in controls:\n",
    "        t = (tag.get(\"type\") or \"\").lower()\n",
    "        if tag.name == \"input\" and t in {\"submit\", \"button\", \"reset\", \"image\", \"hidden\"}:\n",
    "            continue\n",
    "\n",
    "        name = tag.get(\"name\")\n",
    "        # If radio/checkbox with a name, group them\n",
    "        if tag.name == \"input\" and t in {\"radio\", \"checkbox\"} and name:\n",
    "            groups.setdefault((\"group\", name), []).append(tag)\n",
    "        else:\n",
    "            groups[(\"single\", id(tag))] = [tag]\n",
    "\n",
    "    for kind, members in groups.items():\n",
    "        tag = members[0]\n",
    "        t = (tag.get(\"type\") or \"\").lower()\n",
    "        name = tag.get(\"name\") or tag.get(\"id\") or \"\"\n",
    "\n",
    "        # Determine input_type + question text\n",
    "        if kind[0] == \"group\":\n",
    "            input_type = \"radio\" if t == \"radio\" else \"checkbox\"\n",
    "            question_text = get_label_for_input(tag)\n",
    "            key_base = normalize_key(name) or normalize_key(question_text)\n",
    "            # options from each member\n",
    "            opts = []\n",
    "            for m in members:\n",
    "                opt_label = option_text_for_input(m, doc_root)\n",
    "                if opt_label:\n",
    "                    opts.append(opt_label)\n",
    "            # uniquify key\n",
    "            key = key_base\n",
    "            i = 2\n",
    "            while key in seen_keys:\n",
    "                key = f\"{key_base}_{i}\"\n",
    "                i += 1\n",
    "        else:\n",
    "            # single control (text/select/textarea/other)\n",
    "            if tag.name == \"select\":\n",
    "                input_type = \"select\"\n",
    "            elif tag.name == \"textarea\":\n",
    "                input_type = \"textarea\"\n",
    "            elif tag.name == \"input\":\n",
    "                if t in {\"text\",\"number\",\"email\",\"date\",\"time\",\"tel\",\"url\"}:\n",
    "                    input_type = \"text\"\n",
    "                else:\n",
    "                    input_type = t or \"text\"\n",
    "            else:\n",
    "                input_type = \"text\"\n",
    "\n",
    "            question_text = get_label_for_input(tag)\n",
    "            key_base = normalize_key(name) or normalize_key(question_text)\n",
    "            key = key_base or \"field\"\n",
    "            i = 2\n",
    "            while key in seen_keys:\n",
    "                key = f\"{key_base}_{i}\"\n",
    "                i += 1\n",
    "\n",
    "            # options for select only\n",
    "            opts = []\n",
    "            if tag.name == \"select\":\n",
    "                for opt in tag.find_all(\"option\"):\n",
    "                    txt = option_text_for_input(opt, doc_root)\n",
    "                    if txt:\n",
    "                        opts.append(txt)\n",
    "\n",
    "        seen_keys.add(key)\n",
    "        questions.append({\n",
    "            \"key\": key,\n",
    "            \"question\": question_text,\n",
    "            \"input_type\": input_type,\n",
    "            \"options\": opts\n",
    "        })\n",
    "\n",
    "    # Sort for stability\n",
    "    questions.sort(key=lambda d: d[\"key\"])\n",
    "    return questions\n",
    "\n",
    "def build_prompt(transcription: str, questions: list) -> str:\n",
    "    \"\"\"\n",
    "    Build a strict instruction prompt. The model must return EXACTLY one JSON object\n",
    "    with keys equal to the 'key' values below. If a value is not present in the\n",
    "    transcription, return \"NA\". If options are provided, prefer choosing from them.\n",
    "    \"\"\"\n",
    "    # Prepare a minimal schema description to guide the model\n",
    "    lines = []\n",
    "    for q in questions:\n",
    "        if q[\"options\"]:\n",
    "            lines.append(f\"- {q['key']}: {q['question']} (choose from: {', '.join(q['options'])}; if multiple, join with ';')\")\n",
    "        else:\n",
    "            lines.append(f\"- {q['key']}: {q['question']}\")\n",
    "    schema_hint = \"\\n\".join(lines)\n",
    "    allowed_keys = [q[\"key\"] for q in questions]\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert annotator. Fill out a fixed survey based ONLY on the transcription.\\n\\n\"\n",
    "        \"RULES:\\n\"\n",
    "        \"1) Output EXACTLY ONE JSON object.\\n\"\n",
    "        \"2) Use ONLY the keys listed in allowed_keys. Do not invent, rename, or omit keys.\\n\"\n",
    "        \"3) If a value is missing in the transcription, return \\\"NA\\\".\\n\"\n",
    "        \"4) Return strings for all values. For multi-select, join choices with semicolons.\\n\"\n",
    "        \"5) Prefer concise, direct answers.\\n\\n\"\n",
    "        f\"allowed_keys = {json.dumps(allowed_keys, ensure_ascii=False)}\\n\\n\"\n",
    "        \"key → question (and any options):\\n\"\n",
    "        f\"{schema_hint}\\n\\n\"\n",
    "        \"TRANSCRIPTION:\\n\"\n",
    "        f\"'''{transcription}'''\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Build canonical questions from the survey HTML\n",
    "# --------------------------------------------------------------------------------\n",
    "with open(SURVEY_HTML_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_text = f.read()\n",
    "\n",
    "questions = parse_survey_questions(html_text)\n",
    "if not questions:\n",
    "    raise RuntimeError(\"No questions found in the survey HTML.\")\n",
    "\n",
    "print(f\"Found {len(questions)} questions.\")\n",
    "print(\"First few keys:\", [q[\"key\"] for q in questions[:10]])\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Ask the model to answer all questions for each transcription\n",
    "# --------------------------------------------------------------------------------\n",
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    transcription = r[\"transcription\"]\n",
    "    filename = r[\"filename\"]\n",
    "\n",
    "    prompt = build_prompt(transcription, questions)\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You return a single JSON object with exactly the allowed keys.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = resp.choices[0].message.content.strip()\n",
    "\n",
    "    # Parse JSON (the response_format should ensure valid JSON)\n",
    "    try:\n",
    "        obj = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        # last-ditch: try to extract {...}\n",
    "        m = re.search(r\"\\{.*\\}\", content, flags=re.DOTALL)\n",
    "        if not m:\n",
    "            raise\n",
    "        obj = json.loads(m.group(0))\n",
    "\n",
    "    # Coerce to the canonical schema\n",
    "    row = {\"filename\": filename}\n",
    "    for q in questions:\n",
    "        key = q[\"key\"]\n",
    "        val = obj.get(key, \"NA\")\n",
    "        if val is None or (isinstance(val, str) and not val.strip()):\n",
    "            val = \"NA\"\n",
    "        if isinstance(val, list):\n",
    "            val = \";\".join(str(x) for x in val)\n",
    "        else:\n",
    "            val = str(val)\n",
    "        row[key] = val\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Save final CSV\n",
    "# --------------------------------------------------------------------------------\n",
    "final_cols = [\"filename\"] + [q[\"key\"] for q in questions]\n",
    "final_df = pd.DataFrame(rows, columns=final_cols)\n",
    "final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"✅ Wrote {len(final_df)} rows to {OUTPUT_CSV_PATH}\")\n",
    "print(f\"Columns: {len(final_df.columns)}\")\n",
    "print(final_df.columns.tolist()[:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef641ba-e60c-47c5-a190-225f972b808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
